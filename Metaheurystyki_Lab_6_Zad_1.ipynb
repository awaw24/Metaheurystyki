{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/0OManrpfzS4imHnpRHlU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaw24/Metaheurystyki/blob/main/Metaheurystyki_Lab_6_Zad_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poniższy kod w języku Python zawiera implementację algorytmu CLONALG wraz z przykładowymi badaniami na funkcji Rastrigina (10 wymiarów). Wykorzystane zostały trzy zestawy parametrów (rozmiar populacji, liczba najlepszych osobników, liczba iteracji) natomiast każda z konfiguracji została uruchomiona 5‑krotnie, by uzyskać średnie oraz odchylenia najlepszych wyników.\n",
        "\n",
        "Kod zawiera:\n",
        "\n",
        "Definicję funkcji Rastrigina.\n",
        "\n",
        "Implementację algorytmu CLONALG:\n",
        "- inicjalizacja\n",
        "- selekcja klonalna\n",
        "- klonowanie\n",
        "- hipermutacja\n",
        "- dojrzewanie\n",
        "- wymiana losowa\n",
        "\n",
        "Pętlę eksperymentalną generującą tabelę wyników (średnie, odchylenia).\n",
        "\n",
        "Ponizej kodu znajduje się komentarz do uzyskanych przezemnie wyników."
      ],
      "metadata": {
        "id": "J1W0Fo8ZI4-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHiIMSAfFA07",
        "outputId": "b5a74ff6-cd73-4463-d9b1-e9c9382fead3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pop_size  n_best  iters  mean_best   std_best\n",
            "0        50       5    100  65.893146  13.766196\n",
            "1       100      10    200  45.026157   8.754860\n",
            "2       200      20    300  37.650506   6.271854\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Funkcje testowe\n",
        "def rastrigin(x):\n",
        "    n = len(x)\n",
        "    return 10*n + np.sum(x**2 - 10*np.cos(2*np.pi*x))\n",
        "\n",
        "# Implementacja CLONALG\n",
        "def clonalg(func, bounds, dim, pop_size, n_best, max_iter, random_replace, clone_factor=0.1, mutate_factor=0.5):\n",
        "    # Inicjalizacja populacji\n",
        "    pop = np.random.uniform(bounds[0], bounds[1], (pop_size, dim))\n",
        "    fitness = np.apply_along_axis(func, 1, pop)\n",
        "\n",
        "    best_history = []\n",
        "    for it in range(max_iter):\n",
        "        # Wybór najlepszych n_best\n",
        "        idx = np.argsort(fitness)\n",
        "        best_idx = idx[:n_best]\n",
        "        best = pop[best_idx]\n",
        "        best_f = fitness[best_idx]\n",
        "        # Klonowanie proporcjonalnie do pokrewieństwa\n",
        "        affinities = 1/(1+best_f)\n",
        "        clones = []\n",
        "        for i, indiv in enumerate(best):\n",
        "            n_clones = int(np.ceil(clone_factor * affinities[i] * pop_size))\n",
        "            clones.extend([indiv.copy() for _ in range(n_clones)])\n",
        "        clones = np.array(clones)\n",
        "        # Hipermutacja\n",
        "        clone_fit = np.apply_along_axis(func, 1, clones)\n",
        "        for i in range(len(clones)):\n",
        "            rate = mutate_factor * (1 - affinities[i % n_best])\n",
        "            clones[i] += rate * np.random.randn(dim)\n",
        "            clones[i] = np.clip(clones[i], bounds[0], bounds[1])\n",
        "        # Ocena klonów\n",
        "        clone_fit = np.apply_along_axis(func, 1, clones)\n",
        "        # Wybór najlepszych klonów\n",
        "        combined = np.vstack([pop, clones])\n",
        "        comb_fit = np.concatenate([fitness, clone_fit])\n",
        "        idx2 = np.argsort(comb_fit)\n",
        "        pop = combined[idx2][:pop_size]\n",
        "        fitness = comb_fit[idx2][:pop_size]\n",
        "        # Zastąpienie najgorszych losowych rozwiązań\n",
        "        worst = pop_size - random_replace\n",
        "        pop[worst:] = np.random.uniform(bounds[0], bounds[1], (random_replace, dim))\n",
        "        fitness[worst:] = np.apply_along_axis(func, 1, pop[worst:])\n",
        "        best_history.append(fitness.min())\n",
        "    return pop, fitness, best_history\n",
        "\n",
        "# Eksperyment\n",
        "if __name__ == '__main__':\n",
        "    dim = 10\n",
        "    bounds = (-5.12, 5.12)\n",
        "    func = rastrigin\n",
        "    # Zestaw parametrów: (pop_size, n_best, iter)\n",
        "    params = [\n",
        "        (50, 5, 100),\n",
        "        (100, 10, 200),\n",
        "        (200, 20, 300)\n",
        "    ]\n",
        "    results = []\n",
        "    for pop_size, n_best, iters in params:\n",
        "        runs = []\n",
        "        for run in range(5):\n",
        "            pop, fit, hist = clonalg(func, bounds, dim, pop_size, n_best, iters, random_replace=int(0.1*pop_size))\n",
        "            runs.append(fit.min())\n",
        "        results.append({\n",
        "            'pop_size': pop_size,\n",
        "            'n_best': n_best,\n",
        "            'iters': iters,\n",
        "            'mean_best': np.mean(runs),\n",
        "            'std_best': np.std(runs)\n",
        "        })\n",
        "    df = pd.DataFrame(results)\n",
        "    print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**Komentarz do uzyskanych wyników:**\n",
        "\n",
        "<br>\n",
        "\n",
        "**Wpływ wielkości populacji i liczby iteracji**\n",
        "\n",
        "Wraz ze wzrostem rozmiaru populacji (50 → 100 → 200) i liczby iteracji (100 → 200 → 300) obserwujemy istotne obniżenie wartości średniego najlepszego rozwiązania:\n",
        "\n",
        "- Dla najmniejszego zestawu (50, 5, 100) średnia to ≈ 65.9,\n",
        "\n",
        "- Dla środkowego (100, 10, 200) — ≈ 45.0,\n",
        "\n",
        "- Dla największego (200, 20, 300) — ≈ 37.7.\n",
        "To potwierdza, że większa populacja i dłuższy czas ewolucji dają algorytmowi więcej szans na przeszukanie przestrzeni rozwiązań i lepsze przybliżenie minimum.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Redukcja zmienności wyników**\n",
        "\n",
        "Jednocześnie odchylenie standardowe najlepszych wyników (std_best) systematycznie spada: z ~13.8 dla najmniejszego zestawu, przez ~8.75, aż do ~6.27 dla największego. Mniejsza wariancja wskazuje, że konfiguracje o większej populacji i więcej iteracjach dają nie tylko lepsze, ale też bardziej stabilne rezultaty między kolejnymi powtórzeniami.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Malejące zyski**\n",
        "\n",
        "Chociaż kolejne zwiększanie parametrów poprawia wyniki, przyrost korzyści maleje: różnica w mean_best między zestawem 1 a 2 to ~20.9, a między 2 i 3 – już tylko ~7.4. Sugeruje to, że po pewnym poziomie dalsze powiększanie populacji lub wydłużanie iteracji będzie miało coraz mniejszy wpływ na poprawę jakości rozwiązania.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Podsumowanie**\n",
        "\n",
        "- Jeśli celam jest głównie maksymalizacja jakości należy zastosować większe populacje i więcej iteracji, o ile pozwala na to budżet obliczeniowy.\n",
        "\n",
        "- Kompromis między czasem a rozwiązaniem, konfiguracja (100, 10, 200) wydaje się rozsądnym punktem startowym: znacząco lepsza od najmniejszej, ale przy relatywnie umiarkowanym czasie obliczeń.\n",
        "\n",
        "- Testy wskazują, iż większe zasoby (populacja, iteracje) przekładają się na lepsze i bardziej spójne wyniki, ale z malejącym przyrostem zwrotu."
      ],
      "metadata": {
        "id": "tOHSy0UiGHy9"
      }
    }
  ]
}